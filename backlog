
- adversarial
    https://nicholas.carlini.com/code/audio_adversarial_examples/
- add links:
    https://developer.nvidia.com/cudnn
    https://keras.io/getting-started/faq/#data-parallelism
- how lstm interpret independent signals
- implement ctc decoder
    Nvidia also provides a GPU implementation of CTC in cuDNN versions 7 and up. 6
- przykładowe zwroty:
    * zasady gramatyki "ó/u" (słowa spoza słownika)
    * mask phonem ("kupiłem da ciebie")
    * zlepione z przedrostkiem "przede wszystkim" (i nie wystepuje w słowniku)
    * słowa obcego pochodzenia ("stephan antiga")
- measure the sample information entropy and use only which contains the most information
- external model to cover specific phonems
- synthesized data:
    remove samples from synthesized corpus with english names (high WER and CER)
    double char can no be recognized
- circular networks -> LSTM keeps vector and we can measure his trajectory, maybe we can describe it as sin function
- sprawdzić jak dystrybucja batch wer results się zmienia
- evaluate saved model on clarin examples in training set (has to be nromalized using base stats)
- model vizualization
- to en
- extended cost function
  add additional alligmnet which can be decoded using external decoder to correct alligments
  * start with simple "u" and "ó" case
- inspect why clarin prediction is much worst
- finetune learned model to Clarin-PL
- spell words with `rz` and `ż` x10 and check where activation is different
- understand model: LSTM wegihts trajectory
- package: create deepspeech-keras package
- save weights: put pretrained models to server
- callback: weights update
- test: pytest order manage
- how strides (window size) change impact on prediction density of prediction matrix
- clean environment files (delete unnecessary) + add dataclasses
- interactive plotting (zoom-in ect): bokeh vs plotly
- segmentacja próbek przyjaciół
- bigger dev jurisdic set
- understand model: cluster FC activations -> clusters are more informative in following layers?
- change CNN to small FC + LSTM
- different languages support -> en / fr / de + banchmarks
- combine spectrogram and predicted probabilities and create mean spectrogram for the each letter (listen audio files) (cluster letters spectrogram's)
- trian uploaded model with batch normalization on the input layer (no need to normalize features)
language model:
(This two methods can be combine later)
- generate more data from text - Synthetic Speech Pretraining
    how generate?
        a) TTS
        b) quasi CNN features generator via char features
            * phonems are not only in the range of one time step

- freeze char/subwords embeddings in softmax layer
    (does not work) a) unigrams
    b) subword lanugage model: 3tri gram embeddings in softmax
        * how to train emebddings and what properties they should have
Całą implementację można znaleźć: DeepSpeech-Keras
