
\chapter{Conclusion and Future Works}\label{ch:conclusion-and-future-works}

The presented \textit{Synthetic~Boosted~Model} has successfully improved
the performance of the automatic speech recognition \textit{end-to-end} neural network model.
The vast amount of synthetic data can be used to increase the language information supplied to the model.
The improvement is achieved thanks to the new model architecture, the new objective function,
and the new training policy.
However, each component in the presented \textit{Synthetic~Boosted} approach can be further improved.
To start exploring further ideas, we encourage to visit and benefit from our open-source project
\href{https://github.com/rolczynski/Synthetic-Boosted-DeepSpeech}{Synthetic Boosted DeepSpeech}, where
one can find the implementation of the entire system presented in this work, and more.
The pre-trained models are publicly available and ready to use.

\vspace{0.5cm}
\noindent\textbf{Model Architecture} \\
The~\textit{Synthetic~Boosted} approach can be further explored independently to the model architecture.
The research of using the~\textit{Synthetic~Boosted} method in the~\textit{Sequence-to-Sequence} models
should be profoundly investigated.

\vspace{0.5cm}
\noindent\textbf{Adversarial Component} \\
In our work, we introduce the naive adversarial component as the part of the new objective function.
However, we deeply believe that more accurate function exist, and should be applied.

\vspace{0.5cm}
\noindent\textbf{Specialized Domain Adaptation} \\
The \textit{Synthetic~Boosted} approach can be used as an auxiliary data augmentation method.
This method could turn out to be accurate to perform the specialized domain adaptation.
The \textit{Synthetic~Boosted} approach should be tested on different languages and specialized datasets.
